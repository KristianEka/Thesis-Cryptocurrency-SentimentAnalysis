{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thhABeprZU60"
   },
   "source": [
    "# **Library Installation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "arGsYkHVZI2L"
   },
   "outputs": [],
   "source": [
    "# Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "H6am0RGdaUx5"
   },
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CjzRXABZXxS"
   },
   "source": [
    "# **Read Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "OwGurEKXZZFM",
    "outputId": "3ce984e4-b6cb-4c02-808b-eaf4328beca3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>vader_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Token: $GROK24 - Grok 2024 Network: Ethereum ...</td>\n",
       "      <td>token grok grok network ethereum contract xccc...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@metaversejoji Let's check @SolanaMono $SOL #W...</td>\n",
       "      <td>let check sol</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Day's DCA: $BTC, $ATOM, $DVPN, $AXL, $JKL, $HU...</td>\n",
       "      <td>day dca btc atom dvpn axl jkl huahua</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@BorkSOL @Cerita_Crypto @solana @aeyakovenko Y...</td>\n",
       "      <td>project really amazing thats followed send please</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üëâ WL FOR .0 SOL MINT üëà üëâ40 HOURS TILL SNAPSHOT...</td>\n",
       "      <td>sol mint hour till snapshot requirement join d...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9879</th>\n",
       "      <td>CyberKong VX #11328 was adopted for  0.18 $ETH...</td>\n",
       "      <td>cyberkong adopted eth blur</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9880</th>\n",
       "      <td>BULLISH ON SOLANA BULLISH ON JUP BULLISH ON MA...</td>\n",
       "      <td>bullish solana bullish jup bullish madlads</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9881</th>\n",
       "      <td>@naija_bitcoin üçøüçøüçøüçøüçø rd to 3k before valentine...</td>\n",
       "      <td>valentine</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9882</th>\n",
       "      <td>Binance Futures #KLAY/ #USDT Take-Profit targe...</td>\n",
       "      <td>binance future takeprofit target profit period...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9883</th>\n",
       "      <td>@Ta_hmid @Starknet You most likely in the luck...</td>\n",
       "      <td>likely lucky one</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9843 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              full_text  \\\n",
       "0     'Token: $GROK24 - Grok 2024 Network: Ethereum ...   \n",
       "1     @metaversejoji Let's check @SolanaMono $SOL #W...   \n",
       "2     Day's DCA: $BTC, $ATOM, $DVPN, $AXL, $JKL, $HU...   \n",
       "3     @BorkSOL @Cerita_Crypto @solana @aeyakovenko Y...   \n",
       "4     üëâ WL FOR .0 SOL MINT üëà üëâ40 HOURS TILL SNAPSHOT...   \n",
       "...                                                 ...   \n",
       "9879  CyberKong VX #11328 was adopted for  0.18 $ETH...   \n",
       "9880  BULLISH ON SOLANA BULLISH ON JUP BULLISH ON MA...   \n",
       "9881  @naija_bitcoin üçøüçøüçøüçøüçø rd to 3k before valentine...   \n",
       "9882  Binance Futures #KLAY/ #USDT Take-Profit targe...   \n",
       "9883  @Ta_hmid @Starknet You most likely in the luck...   \n",
       "\n",
       "                                         processed_text vader_sentiment  \n",
       "0     token grok grok network ethereum contract xccc...        Positive  \n",
       "1                                         let check sol         Neutral  \n",
       "2                  day dca btc atom dvpn axl jkl huahua         Neutral  \n",
       "3     project really amazing thats followed send please        Positive  \n",
       "4     sol mint hour till snapshot requirement join d...        Positive  \n",
       "...                                                 ...             ...  \n",
       "9879                         cyberkong adopted eth blur         Neutral  \n",
       "9880         bullish solana bullish jup bullish madlads         Neutral  \n",
       "9881                                          valentine         Neutral  \n",
       "9882  binance future takeprofit target profit period...        Positive  \n",
       "9883                                   likely lucky one        Positive  \n",
       "\n",
       "[9843 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_excel('XCleanCryptocurrencyDataset.xlsx', index_col=0)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iK96gIM6ZcpR"
   },
   "source": [
    "# **Data Splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "2qZ8YkqjZhMl"
   },
   "outputs": [],
   "source": [
    "# Asumsikan df adalah DataFrame Anda yang sudah dimuat\n",
    "X = df['processed_text']  # Kolom teks yang sudah diproses\n",
    "y = df['vader_sentiment']  # Target/Label\n",
    "\n",
    "# Encoding target\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "# Tokenisasi dan pembuatan sequences\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "X_padded = pad_sequences(sequences, maxlen=100)  # Sesuaikan maxlen sesuai dengan kebutuhan\n",
    "\n",
    "# Splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# Batasan feature selection\n",
    "dim = X_train.shape[1]  # Jumlah token maksimal dalam sequences\n",
    "lb = [0] * dim\n",
    "ub = [1] * dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3iwrBTfWZgMM"
   },
   "source": [
    "# **Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "UXF-R-Tccn71"
   },
   "outputs": [],
   "source": [
    "def objective_function(weights):\n",
    "    # Memilih fitur berdasarkan bobot feature selection\n",
    "    # Dalam konteks ini, weights akan menentukan embedding tokens yang akan digunakan\n",
    "    selected_indices = np.where(weights > 0.5)[0]\n",
    "    X_train_selected = X_train[:, selected_indices]\n",
    "    X_test_selected = X_test[:, selected_indices]\n",
    "\n",
    "    # Definisikan dan latih model LSTM di sini\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=5000, output_dim=50, input_length=len(selected_indices)),  # Sesuaikan parameter\n",
    "        LSTM(50, dropout=0.2, recurrent_dropout=0.2),\n",
    "        Dense(y_train.shape[1], activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train_selected, y_train, epochs=3, batch_size=64, verbose=0)  # Kurangi epoch untuk kecepatan\n",
    "\n",
    "    # Evaluasi model\n",
    "    loss, accuracy = model.evaluate(X_test_selected, y_test, verbose=0)\n",
    "    return -accuracy  # Negatif karena kita ingin memaksimalkan akurasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shMg_07NbzFn"
   },
   "source": [
    "# Particle Swarm Optimization (PSO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "nWY9-wy8btjk"
   },
   "outputs": [],
   "source": [
    "def pso(func, lb, ub, ieqcons=[], f_ieqcons=None, args=(), kwargs={}, swarmsize=100, omega=0.5, phip=0.5, phig=0.5, maxiter=100, minstep=1e-8, minfunc=1e-8, debug=False):\n",
    "    \"\"\"\n",
    "    Perform a particle swarm optimization (PSO)\n",
    "\n",
    "    Parameters:\n",
    "    - func: function to be minimized\n",
    "    - lb: lower bounds of the design variables\n",
    "    - ub: upper bounds of the design variables\n",
    "    - ieqcons: list of inequality constraint functions (optional)\n",
    "    - f_ieqcons: function returning a list of inequality constraints (optional)\n",
    "    - args: additional arguments passed to func and f_ieqcons\n",
    "    - kwargs: additional keyword arguments passed to func and f_ieqcons\n",
    "    - swarmsize: number of particles in the swarm\n",
    "    - omega: particle velocity scaling factor\n",
    "    - phip: scaling factor to search away from the particle's best known position\n",
    "    - phig: scaling factor to search away from the swarm's best known position\n",
    "    - maxiter: maximum number of iterations\n",
    "    - minstep: minimum step size of swarm's best position before the search terminates\n",
    "    - minfunc: minimum change of swarm's best objective value before the search terminates\n",
    "    - debug: if True, progress statements will be displayed every iteration\n",
    "\n",
    "    Returns:\n",
    "    - g: the swarm's best known position (optimal design)\n",
    "    - f: the objective value at g\n",
    "    \"\"\"\n",
    "    dim = len(lb)\n",
    "    # Initialize the particle positions and their velocities\n",
    "    positions = np.random.uniform(low=lb, high=ub, size=(swarmsize, dim))\n",
    "    velocities = np.zeros((swarmsize, dim))\n",
    "    # Initialize the global and local best positions\n",
    "    personal_best_positions = positions.copy()\n",
    "    personal_best_values = np.array([np.inf for _ in range(swarmsize)])\n",
    "    global_best_value = np.inf\n",
    "    global_best_position = None\n",
    "\n",
    "    for iteration in range(maxiter):\n",
    "        # Update velocities and positions\n",
    "        for i in range(swarmsize):\n",
    "            r_p, r_g = np.random.rand(dim), np.random.rand(dim)\n",
    "            velocities[i] = omega * velocities[i] + \\\n",
    "                            phip * r_p * (personal_best_positions[i] - positions[i]) + \\\n",
    "                            phig * r_g * (global_best_position - positions[i]) if global_best_position is not None else 0\n",
    "            positions[i] += velocities[i]\n",
    "            positions[i] = np.clip(positions[i], lb, ub)  # Keep within bounds\n",
    "\n",
    "            # Evaluate the fitness\n",
    "            value = func(positions[i], *args, **kwargs)\n",
    "            # Update the personal best\n",
    "            if value < personal_best_values[i]:\n",
    "                personal_best_positions[i] = positions[i]\n",
    "                personal_best_values[i] = value\n",
    "            # Update the global best\n",
    "            if value < global_best_value:\n",
    "                global_best_position = positions[i]\n",
    "                global_best_value = value\n",
    "\n",
    "        if debug:\n",
    "            print(f\"Iteration {iteration}: Best Value = {global_best_value}\")\n",
    "\n",
    "        # Check for early stopping criteria\n",
    "        if np.abs(global_best_value - personal_best_values.min()) < minfunc or np.linalg.norm(velocities.max()) < minstep:\n",
    "            break\n",
    "\n",
    "    return global_best_position, global_best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "_o1iOoe0cev3",
    "outputId": "942c92dc-b087-4127-908c-646e16de8f7e"
   },
   "outputs": [],
   "source": [
    "# Jalankan PSO\n",
    "optimizer_results_pso = pso(func=objective_function, lb=lb, ub=ub, swarmsize=10, maxiter=50)  # Kurangi untuk kecepatan\n",
    "# 10-20 partikel dan 50-100 iterasi \n",
    "best_weights_pso = optimizer_results_pso[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Emp2ujPb3jy"
   },
   "source": [
    "# Ant Colony Optimization (ACO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ub7iI196b-yB"
   },
   "outputs": [],
   "source": [
    "def aco(func, lb, ub, ants=100, maxiter=100, alpha=1.0, beta=2.0, evaporation_rate=0.5, pheromone_deposit=0.1, debug=False):\n",
    "    \"\"\"\n",
    "    Perform an Ant Colony Optimization (ACO)\n",
    "\n",
    "    Parameters:\n",
    "    - func: The function to be minimized\n",
    "    - lb: The lower bounds of the design variable(s)\n",
    "    - ub: The upper bounds of the design variable(s)\n",
    "    - ants: The number of ants in the colony (Default: 100)\n",
    "    - maxiter: The maximum number of iterations (Default: 100)\n",
    "    - alpha: Relative importance of pheromone (Default: 1.0)\n",
    "    - beta: Relative importance of heuristic information (Default: 2.0)\n",
    "    - evaporation_rate: Rate at which pheromone evaporates (Default: 0.5)\n",
    "    - pheromone_deposit: Amount of pheromone deposited by ants (Default: 0.1)\n",
    "    - debug: If True, progress statements will be displayed (Default: False)\n",
    "\n",
    "    Returns:\n",
    "    - The best known position and objective value\n",
    "    \"\"\"\n",
    "    # Initialize variables\n",
    "    dim = len(lb)\n",
    "    pheromone_levels = np.ones((ants, dim))\n",
    "    best_val = np.inf\n",
    "    best_pos = None\n",
    "\n",
    "    # Main ACO loop\n",
    "    for iteration in range(maxiter):\n",
    "        positions = np.random.uniform(low=lb, high=ub, size=(ants, dim))\n",
    "        for ant in range(ants):\n",
    "            val = func(positions[ant])\n",
    "            if val < best_val:\n",
    "                best_val = val\n",
    "                best_pos = positions[ant]\n",
    "\n",
    "            # Update pheromones\n",
    "            pheromone_levels[ant] += pheromone_deposit\n",
    "\n",
    "        # Evaporate pheromones\n",
    "        pheromone_levels *= (1 - evaporation_rate)\n",
    "\n",
    "        if debug:\n",
    "            print(f\"Iteration {iteration}: Best Value = {best_val}\")\n",
    "\n",
    "    return best_pos, best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HI7uM4mdcTv1"
   },
   "outputs": [],
   "source": [
    "# Jalankan ACO\n",
    "optimizer_results_aco = aco(func=objective_function, lb=lb, ub=ub, ants=50, maxiter=50)  # Kurangi untuk kecepatan\n",
    "\n",
    "best_weights_aco = optimizer_results_aco[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VBNlyX46b7fb"
   },
   "source": [
    "# Cat Swarm Optimization (CSO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S2gAPTPEb_JR"
   },
   "outputs": [],
   "source": [
    "def cso(func, lb, ub, cats=100, maxiter=100, mix_rate=0.5, seeking_memory_pool=5, seeking_range_of_selected_dimension=0.2, counts_of_dimension_to_change=2, debug=False):\n",
    "    \"\"\"\n",
    "    Perform a Cat Swarm Optimization (CSO)\n",
    "\n",
    "    Parameters:\n",
    "    - func: The function to be minimized\n",
    "    - lb: The lower bounds of the design variable(s)\n",
    "    - ub: The upper bounds of the design variable(s)\n",
    "    - cats: The number of cats in the swarm (Default: 100)\n",
    "    - maxiter: The maximum number of iterations (Default: 100)\n",
    "    - mix_rate: Mixture rate to switch between seeking and tracing modes (Default: 0.5)\n",
    "    - seeking_memory_pool: Size of memory pool in seeking mode (Default: 5)\n",
    "    - seeking_range_of_selected_dimension: Range of selected dimension in seeking mode (Default: 0.2)\n",
    "    - counts_of_dimension_to_change: Number of dimensions to change in seeking mode (Default: 2)\n",
    "    - debug: If True, progress statements will be displayed (Default: False)\n",
    "\n",
    "    Returns:\n",
    "    - The best known position and objective value\n",
    "    \"\"\"\n",
    "    # Initialize variables\n",
    "    dim = len(lb)\n",
    "    best_val = np.inf\n",
    "    best_pos = None\n",
    "    positions = np.random.uniform(low=lb, high=ub, size=(cats, dim))\n",
    "\n",
    "    # Main CSO loop\n",
    "    for iteration in range(maxiter):\n",
    "        for cat in range(cats):\n",
    "            if np.random.rand() < mix_rate:\n",
    "                # Seeking mode\n",
    "                for _ in range(seeking_memory_pool):\n",
    "                    candidate_position = positions[cat] + np.random.uniform(-1, 1, size=dim) * seeking_range_of_selected_dimension\n",
    "                    candidate_position = np.clip(candidate_position, lb, ub)\n",
    "                    val = func(candidate_position)\n",
    "                    if val < best_val:\n",
    "                        best_val = val\n",
    "                        best_pos = candidate_position\n",
    "            else:\n",
    "                # Tracing mode (simplified as random walk in this example)\n",
    "                positions[cat] += np.random.uniform(-1, 1, size=dim)\n",
    "                positions[cat] = np.clip(positions[cat], lb, ub)\n",
    "                val = func(positions[cat])\n",
    "                if val < best_val:\n",
    "                    best_val = val\n",
    "                    best_pos = positions[cat]\n",
    "\n",
    "        if debug:\n",
    "            print(f\"Iteration {iteration}: Best Value = {best_val}\")\n",
    "\n",
    "    return best_pos, best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dI-hqeWVc98G"
   },
   "outputs": [],
   "source": [
    "# Jalankan CSO\n",
    "optimizer_results_cso = cso(func=objective_function, lb=lb, ub=ub, cats=50, maxiter=50)  # Kurangi untuk kecepatan\n",
    "\n",
    "best_weights_cso = optimizer_results_cso[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oiMhM9xmdDFJ"
   },
   "source": [
    "# **Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkdqyiVUfEzq"
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "HuWcVlqQjGR7"
   },
   "outputs": [],
   "source": [
    "def create_lstm_model(input_length, num_classes):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=5000, output_dim=50, input_length=input_length),\n",
    "        LSTM(50, dropout=0.2, recurrent_dropout=0.2),\n",
    "        Dense(num_classes, activation='softmax' if num_classes > 2 else 'sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy' if num_classes > 2 else 'binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "AF4MgIqijKn8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "99/99 [==============================] - 7s 51ms/step - loss: 0.8990 - accuracy: 0.6066 - val_loss: 0.7626 - val_accuracy: 0.6844\n",
      "Epoch 2/10\n",
      "99/99 [==============================] - 5s 48ms/step - loss: 0.5936 - accuracy: 0.7552 - val_loss: 0.5705 - val_accuracy: 0.7721\n",
      "Epoch 3/10\n",
      "99/99 [==============================] - 5s 48ms/step - loss: 0.3385 - accuracy: 0.8797 - val_loss: 0.5060 - val_accuracy: 0.8127\n",
      "Epoch 4/10\n",
      "99/99 [==============================] - 5s 48ms/step - loss: 0.1915 - accuracy: 0.9397 - val_loss: 0.5072 - val_accuracy: 0.8343\n",
      "Epoch 5/10\n",
      "99/99 [==============================] - 5s 47ms/step - loss: 0.1255 - accuracy: 0.9640 - val_loss: 0.5526 - val_accuracy: 0.8368\n",
      "Epoch 6/10\n",
      "99/99 [==============================] - 5s 47ms/step - loss: 0.0848 - accuracy: 0.9789 - val_loss: 0.6109 - val_accuracy: 0.8292\n",
      "Epoch 7/10\n",
      "99/99 [==============================] - 5s 47ms/step - loss: 0.0676 - accuracy: 0.9830 - val_loss: 0.7077 - val_accuracy: 0.8286\n",
      "Epoch 8/10\n",
      "99/99 [==============================] - 5s 47ms/step - loss: 0.0514 - accuracy: 0.9879 - val_loss: 0.7118 - val_accuracy: 0.8260\n",
      "Epoch 9/10\n",
      "99/99 [==============================] - 5s 47ms/step - loss: 0.0419 - accuracy: 0.9895 - val_loss: 0.8018 - val_accuracy: 0.8267\n",
      "Epoch 10/10\n",
      "99/99 [==============================] - 5s 47ms/step - loss: 0.0351 - accuracy: 0.9927 - val_loss: 0.8365 - val_accuracy: 0.8197\n"
     ]
    }
   ],
   "source": [
    "model_lstm = create_lstm_model(X_train.shape[1], y_train.shape[1])\n",
    "history_lstm = model_lstm.fit(X_train, y_train, validation_split=0.2, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 6ms/step - loss: 0.9311 - accuracy: 0.8136\n",
      "Test Loss: 0.931121289730072\n",
      "Test Accuracy: 0.8136109709739685\n"
     ]
    }
   ],
   "source": [
    "# Evaluasi model\n",
    "loss, accuracy = model_lstm.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "9xl_Th4ZfGMo"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_seq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m([\u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X_train_seq])\n\u001b[0;32m      2\u001b[0m X_train_pad \u001b[38;5;241m=\u001b[39m pad_sequences(X_train_seq, maxlen\u001b[38;5;241m=\u001b[39mmax_length, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m X_test_pad \u001b[38;5;241m=\u001b[39m pad_sequences(X_test_seq, maxlen\u001b[38;5;241m=\u001b[39mmax_length, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_seq' is not defined"
     ]
    }
   ],
   "source": [
    "# max_length = max([len(x) for x in X_train_seq])\n",
    "# X_train_pad = pad_sequences(X_train_seq, maxlen=max_length, padding='post')\n",
    "# X_test_pad = pad_sequences(X_test_seq, maxlen=max_length, padding='post')\n",
    "\n",
    "# # Definisikan model\n",
    "# model_pso_lstm = Sequential([\n",
    "#     # Sesuaikan input_dim dengan ukuran vocabulary atau num_words dan output_dim dengan dimensi embedding\n",
    "#     Embedding(input_dim=5000, output_dim=50, input_length=X_train_selected_pso.shape[1]),\n",
    "#     LSTM(50, dropout=0.2, recurrent_dropout=0.2),\n",
    "#     Dense(y_train.shape[1], activation='softmax')  # Gunakan 'sigmoid' untuk binary, 'softmax' untuk multiclass\n",
    "# ])\n",
    "\n",
    "# model_pso_lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Sesuaikan loss function\n",
    "\n",
    "# # Pelatihan model\n",
    "# history = model_pso_lstm.fit(X_train_selected_pso, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# # Evaluasi model\n",
    "# loss, accuracy = model_pso_lstm.evaluate(X_test_selected_pso, y_test)\n",
    "# print(f\"Test Loss: {loss}\")\n",
    "# print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zY28ggTJezn8"
   },
   "source": [
    "# PSO-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "_6C_ypScdFcA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "99/99 [==============================] - 6s 34ms/step - loss: 0.9079 - accuracy: 0.5936 - val_loss: 0.7618 - val_accuracy: 0.6768\n",
      "Epoch 2/10\n",
      "99/99 [==============================] - 3s 31ms/step - loss: 0.5942 - accuracy: 0.7608 - val_loss: 0.5934 - val_accuracy: 0.7683\n",
      "Epoch 3/10\n",
      "99/99 [==============================] - 3s 32ms/step - loss: 0.3519 - accuracy: 0.8736 - val_loss: 0.5486 - val_accuracy: 0.7911\n",
      "Epoch 4/10\n",
      "99/99 [==============================] - 3s 31ms/step - loss: 0.2078 - accuracy: 0.9346 - val_loss: 0.5566 - val_accuracy: 0.8025\n",
      "Epoch 5/10\n",
      "99/99 [==============================] - 3s 32ms/step - loss: 0.1386 - accuracy: 0.9602 - val_loss: 0.6319 - val_accuracy: 0.8108\n",
      "Epoch 6/10\n",
      "99/99 [==============================] - 3s 32ms/step - loss: 0.0980 - accuracy: 0.9752 - val_loss: 0.7187 - val_accuracy: 0.8032\n",
      "Epoch 7/10\n",
      "99/99 [==============================] - 3s 31ms/step - loss: 0.0784 - accuracy: 0.9787 - val_loss: 0.7785 - val_accuracy: 0.8038\n",
      "Epoch 8/10\n",
      "99/99 [==============================] - 3s 31ms/step - loss: 0.0595 - accuracy: 0.9851 - val_loss: 0.8943 - val_accuracy: 0.8089\n",
      "Epoch 9/10\n",
      "99/99 [==============================] - 3s 32ms/step - loss: 0.0475 - accuracy: 0.9881 - val_loss: 0.9621 - val_accuracy: 0.7994\n",
      "Epoch 10/10\n",
      "99/99 [==============================] - 3s 32ms/step - loss: 0.0435 - accuracy: 0.9892 - val_loss: 1.0216 - val_accuracy: 0.8057\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 1.1294 - accuracy: 0.7953\n",
      "Test Loss: 1.1294374465942383\n",
      "Test Accuracy: 0.7953276038169861\n"
     ]
    }
   ],
   "source": [
    "# Asumsikan best_weights sudah ada\n",
    "selected_indices_pso = np.where(best_weights_pso > 0.5)[0]  # Ambil indeks dengan bobot > 0.5\n",
    "\n",
    "# Memfilter X_train dan X_test berdasarkan fitur terpilih\n",
    "X_train_selected_pso = X_train[:, selected_indices_pso]\n",
    "X_test_selected_pso = X_test[:, selected_indices_pso]\n",
    "\n",
    "# Definisikan model\n",
    "model_pso_lstm = Sequential([\n",
    "    # Sesuaikan input_dim dengan ukuran vocabulary atau num_words dan output_dim dengan dimensi embedding\n",
    "    Embedding(input_dim=5000, output_dim=50, input_length=X_train_selected_pso.shape[1]),\n",
    "    LSTM(50, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(y_train.shape[1], activation='softmax')  # Gunakan 'sigmoid' untuk binary, 'softmax' untuk multiclass\n",
    "])\n",
    "\n",
    "model_pso_lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Sesuaikan loss function\n",
    "\n",
    "# Pelatihan model\n",
    "history = model_pso_lstm.fit(X_train_selected_pso, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluasi model\n",
    "loss, accuracy = model_pso_lstm.evaluate(X_test_selected_pso, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PzSNkG_2e8Mj"
   },
   "source": [
    "# ACO-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RdlIrq0e_ta"
   },
   "outputs": [],
   "source": [
    "# Asumsikan best_weights sudah ada\n",
    "selected_indices_aco = np.where(best_weights_aco > 0.5)[0]  # Ambil indeks dengan bobot > 0.5\n",
    "\n",
    "# Memfilter X_train dan X_test berdasarkan fitur terpilih\n",
    "X_train_selected_aco = X_train[:, selected_indices_aco]\n",
    "X_test_selected_aco = X_test[:, selected_indices_aco]\n",
    "\n",
    "# Definisikan model\n",
    "model_aco_lstm = Sequential([\n",
    "    # Sesuaikan input_dim dengan ukuran vocabulary atau num_words dan output_dim dengan dimensi embedding\n",
    "    Embedding(input_dim=5000, output_dim=128, input_length=X_train_selected_aco.shape[1]),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(y_train.shape[1], activation='softmax')  # Gunakan 'sigmoid' untuk binary, 'softmax' untuk multiclass\n",
    "])\n",
    "\n",
    "model_aco_lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Sesuaikan loss function\n",
    "\n",
    "# Pelatihan model\n",
    "history = model_aco_lstm.fit(X_train_selected_aco, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluasi model\n",
    "loss, accuracy = model_aco_lstm.evaluate(X_test_selected_aco, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wX8D2xXle8bx"
   },
   "source": [
    "# CSO-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KpteoCRQfAJv"
   },
   "outputs": [],
   "source": [
    "# Asumsikan best_weights sudah ada\n",
    "selected_indices_cso = np.where(best_weights_cso > 0.5)[0]  # Ambil indeks dengan bobot > 0.5\n",
    "\n",
    "# Memfilter X_train dan X_test berdasarkan fitur terpilih\n",
    "X_train_selected_cso = X_train[:, selected_indices_cso]\n",
    "X_test_selected_cso = X_test[:, selected_indices_cso]\n",
    "\n",
    "# Definisikan model\n",
    "model_cso_lstm = Sequential([\n",
    "    # Sesuaikan input_dim dengan ukuran vocabulary atau num_words dan output_dim dengan dimensi embedding\n",
    "    Embedding(input_dim=5000, output_dim=128, input_length=X_train_selected_cso.shape[1]),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(y_train.shape[1], activation='softmax')  # Gunakan 'sigmoid' untuk binary, 'softmax' untuk multiclass\n",
    "])\n",
    "\n",
    "model_cso_lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Sesuaikan loss function\n",
    "\n",
    "# Pelatihan model\n",
    "history = model_cso_lstm.fit(X_train_selected_cso, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluasi model\n",
    "loss, accuracy = model_cso_lstm.evaluate(X_test_selected_cso, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
